{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank you for sending us your crns and showing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\r\\nworry not autoconnect lure mode in all ola...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kabaliday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>were in do let us know how we can help</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>done</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Category\n",
       "0  thank you for sending us your crns and showing...         1\n",
       "1  \\r\\nworry not autoconnect lure mode in all ola...         0\n",
       "2                                          kabaliday         0\n",
       "3             were in do let us know how we can help         0\n",
       "4                                               done         0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Text\n",
    "\n",
    "data = pd.read_csv(\"Ola_Category_3000.csv\",encoding='latin1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Category</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank you for sending us your crns and showing...</td>\n",
       "      <td>1</td>\n",
       "      <td>thank you for sending us your crns and showing...</td>\n",
       "      <td>[thank, you, for, sending, us, your, crns, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\r\\nworry not autoconnect lure mode in all ola...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\nworry not autoconnect lure mode in all ola...</td>\n",
       "      <td>[worry, not, autoconnect, lure, mode, in, all,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kabaliday</td>\n",
       "      <td>0</td>\n",
       "      <td>kabaliday</td>\n",
       "      <td>[kabaliday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>were in do let us know how we can help</td>\n",
       "      <td>0</td>\n",
       "      <td>were in do let us know how we can help</td>\n",
       "      <td>[were, in, do, let, us, know, how, we, can, help]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>done</td>\n",
       "      <td>0</td>\n",
       "      <td>done</td>\n",
       "      <td>[done]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  Category  \\\n",
       "0  thank you for sending us your crns and showing...         1   \n",
       "1  \\r\\nworry not autoconnect lure mode in all ola...         0   \n",
       "2                                          kabaliday         0   \n",
       "3             were in do let us know how we can help         0   \n",
       "4                                               done         0   \n",
       "\n",
       "                                               clean  \\\n",
       "0  thank you for sending us your crns and showing...   \n",
       "1  \\r\\nworry not autoconnect lure mode in all ola...   \n",
       "2                                          kabaliday   \n",
       "3             were in do let us know how we can help   \n",
       "4                                               done   \n",
       "\n",
       "                                              tokens  \n",
       "0  [thank, you, for, sending, us, your, crns, and...  \n",
       "1  [worry, not, autoconnect, lure, mode, in, all,...  \n",
       "2                                        [kabaliday]  \n",
       "3  [were, in, do, let, us, know, how, we, can, help]  \n",
       "4                                             [done]  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning Text\n",
    "\n",
    "df_clean = data\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df_clean['clean'] = df_clean['Tweets'].astype('str') \n",
    "df_clean.dtypes\n",
    "\n",
    "df_clean[\"tokens\"] = df_clean[\"clean\"].apply(tokenizer.tokenize)\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Word2Vec\n",
    "\n",
    "import gensim\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44404564, 464410000)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# WORD2VEC()\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer, important for a parameter of the model\n",
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)\n",
    "\n",
    "#BUILD_VOCAB()\n",
    "\n",
    "w2v_model.build_vocab(df_clean[\"tokens\"], progress_per=1000)\n",
    "\n",
    "\n",
    "#TRAIN()\n",
    "\n",
    "w2v_model.train(df_clean[\"tokens\"], total_examples=w2v_model.corpus_count, epochs=10000, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First defining the X (input), and the y (output)\n",
    "\n",
    "y = data['Category'].values\n",
    "X = np.array(df_clean[\"tokens\"])\n",
    "\n",
    "#And here is the train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Vectorizer \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming & Fitting Vectorizer to Train Data\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transforming Vectorizer to Test Data\n",
    "\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 536\n"
     ]
    }
   ],
   "source": [
    "# Getting Number of Features from the Vectorizer \n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Mean Cross-Validation Accuracy\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), X_train, y_train, cv=5)\n",
    "print(\"Mean Cross-Validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.857\n",
      "Testing set score: 0.819\n"
     ]
    }
   ],
   "source": [
    "# Fitting Train Data with Logistic Regression Algorithm\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Testing set score: {:.3f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[ 62  95]\n",
      " [ 13 426]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Sentiments with the Test Data & Creating the Confusion Matrix\n",
    "\n",
    "pred_logreg = logreg.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, pred_logreg)\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.793\n",
      "Testing set score: 0.755\n"
     ]
    }
   ],
   "source": [
    "# Fitting Train Data with Multinomial Naive Bayes Algorithm\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(nb.score(X_train, y_train)))\n",
    "print(\"Testing set score: {:.3f}\".format(nb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[ 21 136]\n",
      " [ 10 429]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Sentiments with the Test Data & Creating the Confusion Matrix\n",
    "\n",
    "pred_nb = nb.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, pred_nb)\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.996\n",
      "Testing set score: 0.834\n"
     ]
    }
   ],
   "source": [
    "# Fitting Train Data with Random Forest Algorithm\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, bootstrap= True, max_features = 'sqrt')\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(rf.score(X_train, y_train)))\n",
    "print(\"Testing set score: {:.3f}\".format(rf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[ 83  74]\n",
      " [ 25 414]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Sentiments with the Test Data & Creating the Confusion Matrix\n",
    "\n",
    "pred_rf = rf.predict(X_test)\n",
    "confusion = confusion_matrix(y_test, pred_rf)\n",
    "print(\"Confusion Matrix: \\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
